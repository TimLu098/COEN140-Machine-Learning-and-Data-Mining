{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc29d72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE LOCATIION: CHANGE BEFORE EACH TEST\n",
    "FOLDER = 'Data3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0076c42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0  index                                         para_array  \\\n",
      "0              0      0  ['Three', 'Rings', 'for', 'the', 'Elven-kings'...   \n",
      "1              1      1  ['When', 'those', 'whose', 'advice', 'and', 'o...   \n",
      "2              2      2  ['It', 'was', 'during', '1944', 'that,', 'leav...   \n",
      "3              3      3  ['As', 'for', 'any', 'inner', 'meaning', 'or',...   \n",
      "4              4      4  ['Other', 'arrangements', 'could', 'be', 'devi...   \n",
      "...          ...    ...                                                ...   \n",
      "4890        4890   5432  ['Elrond', 'greeted', 'them', 'gravely', 'and'...   \n",
      "4891        4891   5433  [\"'So\", 'I', 'thought', 'too,', 'once.', 'But'...   \n",
      "4892        4892   5435  ['But', 'Sam', 'was', 'now', 'sorrowful', 'at'...   \n",
      "4893        4893   5436  ['But', 'to', 'Sam', 'the', 'evening', 'deepen...   \n",
      "4894        4894   5437  ['He', 'drew', 'a', 'deep', 'breath.', \"'Well,...   \n",
      "\n",
      "                                               para_raw              book  \n",
      "0     Three Rings for the Elven-kings under the sky,...  Corpus\\lotr1.txt  \n",
      "1     When those whose advice and opinion I sought c...  Corpus\\lotr1.txt  \n",
      "2     It was during 1944 that, leaving the loose end...  Corpus\\lotr1.txt  \n",
      "3     As for any inner meaning or 'message', it has ...  Corpus\\lotr1.txt  \n",
      "4     Other arrangements could be devised according ...  Corpus\\lotr1.txt  \n",
      "...                                                 ...               ...  \n",
      "4890  Elrond greeted them gravely and graciously, an...  Corpus\\lotr3.txt  \n",
      "4891  'So I thought too, once. But I have been too d...  Corpus\\lotr3.txt  \n",
      "4892  But Sam was now sorrowful at heart, and it see...  Corpus\\lotr3.txt  \n",
      "4893  But to Sam the evening deepened to darkness as...  Corpus\\lotr3.txt  \n",
      "4894  He drew a deep breath. 'Well, I'm back,' he said.  Corpus\\lotr3.txt  \n",
      "\n",
      "[4895 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "from os.path import join\n",
    "import pandas as pd\n",
    "\n",
    "corpus_df = pd.read_csv(join(FOLDER,'corpus_df.csv'))\n",
    "print(corpus_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "471c8776",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[2]\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "#Get the tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "#print(tokenizer)\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a7a42da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[3]\n",
    "\n",
    "import torch\n",
    "\n",
    "#Accumulated batch size\n",
    "def pack_tensor(new_tensor, packed_tensor, max_seq_len):\n",
    "    if packed_tensor is None:\n",
    "        return new_tensor, True, None\n",
    "    if new_tensor.size()[1] + packed_tensor.size()[1] > max_seq_len:\n",
    "        return packed_tensor, False, new_tensor\n",
    "    else:\n",
    "        packed_tensor = torch.cat([new_tensor, packed_tensor[:, 1:]], dim=1)\n",
    "        return packed_tensor, True, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "022c005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[5]\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Story_text(Dataset):\n",
    "    def __init__(self, control_code, truncate = False, gpt2_type=\"gpt2\", max_length=1024):\n",
    "        \n",
    "        self.tokenizer= GPT2Tokenizer.from_pretrained(gpt2_type)\n",
    "        self.raw_para = []\n",
    "        \n",
    "        for row in corpus_df['para_raw']:\n",
    "            self.raw_para.append(torch.tensor(\n",
    "                self.tokenizer.encode(f\"<|{control_code}|{row[:max_length]}<|endoftext|>\")\n",
    "            ))\n",
    "            \n",
    "            \n",
    "        if truncate:\n",
    "            self.raw_para = self.raw_para[:20000]\n",
    "        self.text_count = len(self.raw_para)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.text_count\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        return self.raw_para[item]  \n",
    "\n",
    "dataset = Story_text(corpus_df['para_raw'], truncate= True, gpt2_type= \"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bbc4797",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[6]\n",
    "\n",
    "#dataset = Story_Text class\n",
    "#model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "#tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(\n",
    "    dataset, model, tokenizer,\n",
    "    batch_size=16, epochs=5, lr=2e-5,\n",
    "    max_seq_len=400, warmup_steps=200,\n",
    "    gpt2_type=\"gpt2\", output_dir=\".\", output_prefix=\"wreckgar\",\n",
    "    test_mode=False,save_model_on_epoch=False,\n",
    "):\n",
    "    acc_steps = 100\n",
    "    \n",
    "    device = torch.device(\"cuda\")\n",
    "    model = model.cuda()\n",
    "    #device = torch.device(\"cpu\")\n",
    "    #model = model.cpu()\n",
    "    \n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    #optimizer = AdamW(model.parameters(), lr=lr)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    \n",
    "    # replace AdamW with Adafactor\n",
    "    #optimizer = Adafactor(\n",
    "    #    model.parameters(),\n",
    "    #    lr=1e-3,\n",
    "    #    eps=(1e-30, 1e-3),\n",
    "    #    clip_threshold=1.0,\n",
    "    #    decay_rate=-0.8,\n",
    "    #    beta1=None,\n",
    "    #    weight_decay=0.0,\n",
    "    #    relative_step=False,\n",
    "    #    scale_parameter=False,\n",
    "    #    warmup_init=False,\n",
    "    #)\n",
    "    \n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=warmup_steps, num_training_steps=-1\n",
    "    )\n",
    "\n",
    "    train_dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "    loss=0\n",
    "    accumulating_batch_count = 0\n",
    "    input_tensor = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        print(f\"Training epoch {epoch}\")\n",
    "        print(loss)\n",
    "        for idx, entry in tqdm(enumerate(train_dataloader)):\n",
    "            (input_tensor, carry_on, remainder) = pack_tensor(entry, input_tensor, 768)\n",
    "\n",
    "            if carry_on and idx != len(train_dataloader) - 1:\n",
    "                continue\n",
    "\n",
    "            input_tensor = input_tensor.to(device)\n",
    "            outputs = model(input_tensor, labels=input_tensor)\n",
    "            loss = outputs[0]\n",
    "            loss.backward()\n",
    "\n",
    "            if (accumulating_batch_count % batch_size) == 0:\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "                model.zero_grad()\n",
    "\n",
    "            accumulating_batch_count += 1\n",
    "            \n",
    "            #print(accumulating_batch_count)\n",
    "            \n",
    "            input_tensor = None\n",
    "        if save_model_on_epoch:\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                os.path.join(output_dir, f\"{output_prefix}-{epoch}.pt\"),\n",
    "            )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7489904c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4895it [04:15, 19.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 1\n",
      "tensor(1.9229, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4895it [04:10, 19.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 2\n",
      "tensor(1.7143, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4895it [04:11, 19.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 3\n",
      "tensor(1.8632, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4895it [04:11, 19.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 4\n",
      "tensor(1.9527, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4895it [04:12, 19.36it/s]\n"
     ]
    }
   ],
   "source": [
    "#[7]\n",
    "\n",
    "model = train(dataset, model, tokenizer,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "160959ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to C:\\Users\\tofug\\Anaconda_Projects\\Coen 140\\final_project\\Data2\\trained_model.pt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = os.path.abspath(os.getcwd())\n",
    "torch.save(model.state_dict(), join(path, FOLDER, 'trained_model.pt'))\n",
    "print(\"saved to \" + join(path, FOLDER, 'trained_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ca3f19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

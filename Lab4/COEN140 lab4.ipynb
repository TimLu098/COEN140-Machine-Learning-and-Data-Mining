{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bef8e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1    2    3               4\n",
      "0    5.1  3.5  1.4  0.2     Iris-setosa\n",
      "1    4.9  3.0  1.4  0.2     Iris-setosa\n",
      "2    4.7  3.2  1.3  0.2     Iris-setosa\n",
      "3    4.6  3.1  1.5  0.2     Iris-setosa\n",
      "4    5.0  3.6  1.4  0.2     Iris-setosa\n",
      "..   ...  ...  ...  ...             ...\n",
      "145  6.7  3.0  5.2  2.3  Iris-virginica\n",
      "146  6.3  2.5  5.0  1.9  Iris-virginica\n",
      "147  6.5  3.0  5.2  2.0  Iris-virginica\n",
      "148  6.2  3.4  5.4  2.3  Iris-virginica\n",
      "149  5.9  3.0  5.1  1.8  Iris-virginica\n",
      "\n",
      "[150 rows x 5 columns]\n",
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import pprint\n",
    "import time\n",
    "\n",
    "\n",
    "# load and store dataset from website\n",
    "data = pd.io.parsers.read_csv(filepath_or_buffer='iris.data.txt',header=None, sep=',',\n",
    "    )\n",
    "\n",
    "print(data)\n",
    "print(type(data[0][0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed66b206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0    1    2    3            4\n",
      "35  5.0  3.2  1.2  0.2  Iris-setosa\n",
      "36  5.5  3.5  1.3  0.2  Iris-setosa\n",
      "37  4.9  3.1  1.5  0.1  Iris-setosa\n",
      "38  4.4  3.0  1.3  0.2  Iris-setosa\n",
      "39  5.1  3.4  1.5  0.2  Iris-setosa \n",
      "\n",
      "      0    1    2    3                4\n",
      "85  6.0  3.4  4.5  1.6  Iris-versicolor\n",
      "86  6.7  3.1  4.7  1.5  Iris-versicolor\n",
      "87  6.3  2.3  4.4  1.3  Iris-versicolor\n",
      "88  5.6  3.0  4.1  1.3  Iris-versicolor\n",
      "89  5.5  2.5  4.0  1.3  Iris-versicolor \n",
      "\n",
      "       0    1    2    3               4\n",
      "135  7.7  3.0  6.1  2.3  Iris-virginica\n",
      "136  6.3  3.4  5.6  2.4  Iris-virginica\n",
      "137  6.4  3.1  5.5  1.8  Iris-virginica\n",
      "138  6.0  3.0  4.8  1.8  Iris-virginica\n",
      "139  6.9  3.1  5.4  2.1  Iris-virginica\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timlu\\AppData\\Local\\Temp\\ipykernel_22808\\1682074540.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train = data[0:40].append(data[50:90]).append(data[100:140])\n",
      "C:\\Users\\timlu\\AppData\\Local\\Temp\\ipykernel_22808\\1682074540.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  test  = data[40:50].append(data[90:100]).append(data[140:150])\n"
     ]
    }
   ],
   "source": [
    "# split up 80% of dataset for training and 20% for testing\n",
    "train = data[0:40].append(data[50:90]).append(data[100:140])\n",
    "test  = data[40:50].append(data[90:100]).append(data[140:150])\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "covariance = np.cov(train)\n",
    "\n",
    "# categorize our flowers by their respective class and create separate tables for them\n",
    "setosa = train[train[4] == 'Iris-setosa']\n",
    "print(setosa.tail(),'\\n')\n",
    "versicolor = train[train[4] == 'Iris-versicolor']\n",
    "print(versicolor.tail(),'\\n')\n",
    "virginica = train[train[4] == 'Iris-virginica']\n",
    "print(virginica.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c22bbf5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'setosa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# drop labels so that we only have numerical data for training sets\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_setosa \u001b[38;5;241m=\u001b[39m \u001b[43msetosa\u001b[49m\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;241m4\u001b[39m,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msetosa:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(train_setosa\u001b[38;5;241m.\u001b[39mhead(),\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'setosa' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# drop labels so that we only have numerical data for training sets\n",
    "train_setosa = setosa.drop(4,axis=1)\n",
    "print('setosa:')\n",
    "print(train_setosa.head(),'\\n')\n",
    "train_versicolor = versicolor.drop(4,axis=1)\n",
    "print('versicolor:')\n",
    "print(train_versicolor.head(),'\\n')\n",
    "train_virginica = virginica.drop(4,axis=1)\n",
    "print('virginica:')\n",
    "print(train_virginica.head(),'\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd559c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the probability density function (as noted from Dr. Fang's lectures)\n",
    "def P(x,mean,covariance):\n",
    "    k = x.shape[0]\n",
    "    first = 1/math.sqrt(((2.0*math.pi)**k) * np.linalg.det(covariance)) \n",
    "    second = math.exp(-0.5*np.dot(np.dot((x-mean),np.linalg.inv(covariance)),(x-mean)[np.newaxis].T))\n",
    "    return first*second\n",
    "# in order to use the function from above, we have to calculate the mean for each of the flowers' attributes\n",
    "def my_means(matrix):\n",
    "    means = []\n",
    "    for attribute in matrix.values.T:\n",
    "        means.append(attribute.sum()/float(matrix.shape[0]))\n",
    "    return np.array(means)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ecea461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we also need to calculate the covariances\n",
    "def my_covs(matrix):\n",
    "    mean = my_means(matrix)\n",
    "    # setup each class to have a 4 x 4 matrix for covariance\n",
    "    total_cov = np.zeros((matrix.shape[1],matrix.shape[1]))\n",
    "    for row in range(matrix.shape[0]):\n",
    "        total_cov += np.outer((matrix.iloc[row].values - mean),(matrix.iloc[row].values - mean))\n",
    "    cov = total_cov/float(matrix.shape[0])\n",
    "    return cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "028707d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means:\n",
      "{'setosa': array([5.0375, 3.44  , 1.4625, 0.2325]),\n",
      " 'versicolor': array([6.01  , 2.78  , 4.3175, 1.35  ]),\n",
      " 'virginica': array([6.6225, 2.96  , 5.6075, 1.99  ])}\n",
      "\n",
      "Covariances:\n",
      "{'setosa': array([[0.12784375, 0.0965    , 0.01265625, 0.01328125],\n",
      "       [0.0965    , 0.1294    , 0.002     , 0.0142    ],\n",
      "       [0.01265625, 0.002     , 0.02884375, 0.00446875],\n",
      "       [0.01328125, 0.0142    , 0.00446875, 0.00969375]]),\n",
      " 'versicolor': array([[0.2669    , 0.08445   , 0.167825  , 0.051     ],\n",
      "       [0.08445   , 0.1081    , 0.07885   , 0.04425   ],\n",
      "       [0.167825  , 0.07885   , 0.19844375, 0.071875  ],\n",
      "       [0.051     , 0.04425   , 0.071875  , 0.042     ]]),\n",
      " 'virginica': array([[0.45624375, 0.10765   , 0.34883125, 0.049975  ],\n",
      "       [0.10765   , 0.1104    , 0.07905   , 0.0451    ],\n",
      "       [0.34883125, 0.07905   , 0.33669375, 0.057825  ],\n",
      "       [0.049975  , 0.0451    , 0.057825  , 0.0724    ]])}\n"
     ]
    }
   ],
   "source": [
    "means = {}\n",
    "means['setosa']  = my_means(train_setosa)\n",
    "means['versicolor'] = my_means(train_versicolor)\n",
    "means['virginica'] = my_means(train_virginica)\n",
    "\n",
    "covs = {}\n",
    "covs['setosa'] = my_covs(train_setosa)\n",
    "covs['versicolor'] = my_covs(train_versicolor)\n",
    "covs['virginica'] = my_covs(train_virginica)\n",
    "\n",
    "# this variable is necessary for LDA, since the covariances are assumed to be equal\n",
    "cov_avg = (covs['setosa'] + covs['versicolor'] + covs['virginica'])/3.0\n",
    "\n",
    "# pprint is a module that prints out dictionaries all pretty :D\n",
    "print(\"Means:\")\n",
    "pprint.pprint(means)\n",
    "print(\"\\nCovariances:\")\n",
    "pprint.pprint(covs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "595040f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2\n",
    "\n",
    "def LDA(x, mean, avg_cov):\n",
    "    prob = {}\n",
    "    prob['Iris-setosa'] = P(x,mean['setosa'],avg_cov)\n",
    "    prob['Iris-versicolor'] = P(x,mean['versicolor'],avg_cov)\n",
    "    prob['Iris-virginica'] = P(x,mean['virginica'],avg_cov)\n",
    "    \n",
    "    # key is set to prob.get since we need to compare the values of the dictionary, not the keys\n",
    "    return max(prob, key=prob.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6165bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate for LDA on training subset: 2.5%\n",
      "Error rate for LDA on testing subset: 0.0%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy by comparing LDA/QDA prediction vs actual value\n",
    "def calculate_accuracy(classifier, subset):\n",
    "    n_correct = 0\n",
    "    for row in subset.iterrows():\n",
    "        x = np.array(row[1][0:4])\n",
    "        actual = row[1][4]\n",
    "        # classifier = 1: LDA, classifier = 2: QDA, classifier = 3: QDA with independent features\n",
    "        if classifier == 1:\n",
    "            if LDA(x, means, cov_avg) == actual:\n",
    "                n_correct += 1\n",
    "        elif classifier == 2:\n",
    "            if QDA(x, means, covs) == actual:\n",
    "                n_correct += 1\n",
    "        elif classifier == 3:\n",
    "            if QDA(x, means, indep_covs) == actual:\n",
    "                n_correct += 1\n",
    "        else:\n",
    "            raise ValueError(\"Classifier unknown. Please try again\")\n",
    "    accuracy = (n_correct/float(len(subset)) * 100)\n",
    "    error = 100 - accuracy\n",
    "    return str(error)\n",
    "print(\"Error rate for LDA on training subset: \" + calculate_accuracy(1, train) + \"%\")\n",
    "print(\"Error rate for LDA on testing subset: \" + calculate_accuracy(1, test) + \"%\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14401cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step3\n",
    "def QDA(x, mean, covs):\n",
    "    prob = {}\n",
    "    prob['Iris-setosa'] = P(x,mean['setosa'],covs['setosa'])\n",
    "    prob['Iris-versicolor'] = P(x,mean['versicolor'],covs['versicolor'])\n",
    "    prob['Iris-virginica'] = P(x,mean['virginica'],covs['virginica'])\n",
    "    \n",
    "    # key is set to prob.get since we need to compare the values of the dictionary, not the keys\n",
    "    return max(prob, key=prob.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "143b3c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate for QDA on training subset: 1.6666666666666714%\n",
      "Error rate for QDA on testing subset: 0.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"Error rate for QDA on training subset: \" + calculate_accuracy(2, train) + \"%\")\n",
    "print(\"Error rate for QDA on testing subset: \" + calculate_accuracy(2, test) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b2511fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-setosa error rate: 0.0 %\n",
      "Iris-versicolor error rate: 4.0 %\n",
      "Iris-virginica error rate: 2.0 %\n"
     ]
    }
   ],
   "source": [
    "#step4\n",
    "# do training & testing sets together, rather than separated\n",
    "categories = ['Iris-setosa','Iris-versicolor','Iris-virginica']\n",
    "\n",
    "# run LDA on each separate class\n",
    "for category in categories:\n",
    "    flower_class = data[data[4] == category]\n",
    "    n_correct = 0\n",
    "    for row in flower_class.iterrows():\n",
    "        x = np.array(row[1][0:4])\n",
    "        actual = row[1][4]\n",
    "        predicted = LDA(x,means,cov_avg)\n",
    "        # if predicted answer matches our actual answer, we consider that a success\n",
    "        if predicted == actual:\n",
    "            n_correct += 1\n",
    "    accuracy = (n_correct/float(len(flower_class)) * 100)\n",
    "    error = 100 - accuracy\n",
    "    print(category, \"error rate:\", error, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "abd31940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.12784375 0.         0.         0.        ]\n",
      " [0.         0.1294     0.         0.        ]\n",
      " [0.         0.         0.02884375 0.        ]\n",
      " [0.         0.         0.         0.00969375]]\n",
      "[[0.2669     0.         0.         0.        ]\n",
      " [0.         0.1081     0.         0.        ]\n",
      " [0.         0.         0.19844375 0.        ]\n",
      " [0.         0.         0.         0.042     ]]\n",
      "[[0.45624375 0.         0.         0.        ]\n",
      " [0.         0.1104     0.         0.        ]\n",
      " [0.         0.         0.33669375 0.        ]\n",
      " [0.         0.         0.         0.0724    ]]\n"
     ]
    }
   ],
   "source": [
    "#step5\n",
    "#convert cov matrices to diagonal (set non-diag entries to 0)\n",
    "indep_covs = {}\n",
    "for category, cov in covs.items():\n",
    "    \n",
    "    # setup each category to have a 4 x 4 identity matrix\n",
    "    indep_covs[category] = np.zeros(cov.shape)\n",
    "    \n",
    "    # we should only add the diagonal values from our covariance matrices to our identity matrix\n",
    "    for row in range(cov.shape[0]):\n",
    "        for col in range(cov.shape[1]):\n",
    "            if row == col:\n",
    "                indep_covs[category][row][col] = cov[row][col]\n",
    "    print(indep_covs[category])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6ad2db8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# calculate the time and error rates for QDA \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m qda_start_time \u001b[38;5;241m=\u001b[39m \u001b[43mtime\u001b[49m\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError rate for QDA on training subset: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m calculate_accuracy(\u001b[38;5;241m2\u001b[39m, train) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError rate for QDA on testing subset: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m calculate_accuracy(\u001b[38;5;241m2\u001b[39m, test) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "# calculate the time and error rates for QDA \n",
    "qda_start_time = time.time() * 1000\n",
    "print(\"Error rate for QDA on training subset: \" + calculate_accuracy(2, train) + \"%\")\n",
    "print(\"Error rate for QDA on testing subset: \" + calculate_accuracy(2, test) + \"%\")\n",
    "print(\"Time taken for QDA with features:\", (time.time()*1000)-qda_start_time, \"ms\\n\")\n",
    "\n",
    "# calculate the time and error rates for QDA with independent features\n",
    "indep_start_time = time.time() * 1000\n",
    "print(\"Error rate for QDA on training subset with independent features : \" + calculate_accuracy(3, train) + \"%\")\n",
    "print(\"Error rate for QDA on testing subset with independent features : \" + calculate_accuracy(3, test) + \"%\")\n",
    "print(\"Time taken for QDA with independent features:\", (time.time()*1000)-indep_start_time, \"ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976d6828",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
